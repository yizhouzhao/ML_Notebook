{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib \n",
    "from sklearn.model_selection import train_test_split\n",
    "#Sometimes, pyplot doesn't work if you don't import matplotlib\n",
    "import matplotlib.pyplot as plt, matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background on SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on UC Berkeley Machine Learning Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset:  MNIST\n",
    "\n",
    "Given a set of images, each image is a handwritten number from 0 to 9, the goal is to categorize each image into 10 bins, each corresponding to a digit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Data\n",
    "\n",
    "We use panda's read_csv to read train.csv into a [dataframe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_location = os.path.join(os.getcwd(), \\\n",
    "                                   \"data\", \"train.csv\")\n",
    "test_set_location = os.path.join(os.getcwd(), \\\n",
    "                                 \"data\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are loading csv file into a panda dataframe.  The first column of csv file is label and the rest of the columns represent the pixels of that image.\n",
    "\n",
    "Note [0:5000] is for getting the first 5000 rows and [1:] is getting all the column values other than first column.\n",
    "\n",
    "We then apply provided function to separate the two csv into separate frames: train images, train_labels, test_images, test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karen/anaconda3/envs/MNIST/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "labeled_images = pd.read_csv(train_set_location)\n",
    "images = labeled_images.iloc[0:5000, 1:]\n",
    "labels = labeled_images.iloc[0:5000,:1]\n",
    "train_images, test_images,train_labels, test_labels \\\n",
    "    = train_test_split(images, labels, train_size=0.8, \\\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Image\n",
    "- To view this image in matplotlib, we need to [reshape](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html) into a $28 \\times 28$ matrix.\n",
    "- Note there are 784 columns representing the pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note the dimension of each image is (784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60cbe88668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f60d34bbb70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_index = 0 # We will read the 0th data entry\n",
    "img = train_images.iloc[image_index].as_matrix()\n",
    "\n",
    "print(\"Note the dimension of each image is \" + str(img.shape))\n",
    "\n",
    "# We will reshape img into 28 x 28 matrix\n",
    "img = img.reshape((28, 28))\n",
    "\n",
    "# Showing the image\n",
    "plt.imshow(img, cmap='gray') \n",
    "plt.show()\n",
    "plt.title(train_labels.iloc[image_index, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, what is the work flow?\n",
    "A typical ML program involves two functions: \n",
    "- train(train_dataset, train_label)\n",
    "- predict(test_dataset, learned_parameter)\n",
    "\n",
    "Train will take train_dataset, train_label and return a decision mechanism (usually an array of parameters).  So with the prediction fuction, given a test_dataset, it will return the labels.  \n",
    "\n",
    "Finally, we will compare the returned label with test label to calculate the frequency of correct labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Math behind SVM\n",
    "\n",
    "### Problem Premise\n",
    "\n",
    "Support vector machine is a supervised model that is designed to solve **classification problems.**  Generally, the dataset is in the following form:\n",
    "\n",
    "$$(x_i, y_i) \\text{ where } x_i \\in \\mathbb{R}^m, y_i \\in \\mathbb{R}^{k}$$\n",
    "\n",
    "where *m*  is the number of features and *k* is the number of resulting classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Using Hyperplane as a classifier\n",
    "\n",
    "From the previous section, we know that each image can be represented as a vector $v \\in \\mathbb{R}^m$, where $m$ in this case is $784$.\n",
    "\n",
    "Hence we can represent $v$ as a point in $m$ dimensional space.  (i.e. Note how $(1, 1) \\in \\mathbb{R}^2$ represents a point on a 2 dimensional cartesian plan.)\n",
    "\n",
    "In this problem, we need to classify the images into 10 categories.  Let's first consider a simpler problem, in which we only need to separate the images into two categories: $0$ or not $0$.\n",
    "\n",
    "Since every image can be represented as a $m$ dimensional point, one intuitional classifier is to draw a \"line\" in the vector space $\\mathbb{R}^{m}$, such that every value above $v$ will be classified as $0$ and every value below $v$ will be classified as not $0$.  Such \"line\" is a hyperplane with dimension $n-1$.\n",
    "\n",
    "In two-dimensional case, the \"line\" can be represented as :\n",
    "\n",
    "![svc](svc.png)\n",
    "\n",
    "From linear algebra, a hyperplane of $m-1$ dimension in $m$ dimensional vector space can be represented as\n",
    "\n",
    "$$\\{x \\in \\mathbb{R}^m | c^Tx + b = 0 \\}$$\n",
    "where $b$ is plane's translation from the origin and $c$ is the vector perpendicular to that hyperplane.\n",
    "\n",
    "\n",
    "*Prove that $x' \\in \\mathbb{R}$ is \"above\" the hyperplane, iff $c^Tx + b > 0$*.\n",
    "\n",
    "*Above means point is to the right and above of all points on the plane*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $x' \\in \\mathbb{R}$ is \"above\" the hyperplane, iff $c^Tx + b > 0$ and is \"under\" the hyperplane, iff $c^Tx + b < 0$.  We have a crude classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we know if the classifier is a good classifier?\n",
    "\n",
    "The objective of a good classifier is simple:  correct and efficient.  At this point, we will focus on the correctness of the classifier.\n",
    "\n",
    "Built on top of our crude classifier we will define the following prediction function.\n",
    "\n",
    "```python\n",
    "\n",
    "pred(x):\n",
    "   if c^Tx + b > 0:\n",
    "       return 1\n",
    "    return -1\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margins\n",
    "\n",
    "**Margins** is the distance between the closest data point and the hyperplane.  \n",
    "\n",
    "The **Loss Function** of Support Vector Machine aims to maximize the correctness of classification and maximize the margin.  \n",
    "\n",
    "### Hinge Loss\n",
    "\n",
    "We will define **Hinge Loss** as \n",
    "\n",
    "$$\\max(0, 1 - yf(x))$$\n",
    "\n",
    "given $f(x)$ is $pred(x)$ for the SVM prediction function.  This will ensure mislabeled value to receive a positive loss.  \n",
    "\n",
    "\n",
    "For general case, our loss function will be \n",
    "\n",
    "$$L = \\sum_{i=1}^n \\max(0, 1 - y_if(x_i))$$\n",
    "\n",
    "given n points.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert} $$\n",
    "\n",
    "We assumed so far that $f(x) = c^Tx + b$ with $\\norm{c}_2 = 1$.  Note on the same plane, larger $c$ value will force small $x$ in order to keep $1 - y_if(x_i)$ to be small. Hence, smaller $c$ will have a much larger room for errors. (What happens if $y_i = 1$ and $f(x_i) = -10$ vs $f(x_i) = -1$ and Adding a regularization term $\\lambda \\norm{c}^2$ will allow the classifier to be more lenient.  This is **Soft margin SVM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training using sckitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_images, train_labels.values.ravel())\n",
    "clf.score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karen/anaconda3/envs/MNIST/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/karen/anaconda3/envs/MNIST/lib/python3.5/site-packages/pandas/core/frame.py:2366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "/home/karen/anaconda3/envs/MNIST/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f60c2456d30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEXCAYAAABiaJKRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60d35376a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=0\n",
    "test_images[test_images>0]=1\n",
    "train_images[train_images>0]=1\n",
    "\n",
    "img=train_images.iloc[i].as_matrix().reshape((28,28))\n",
    "plt.imshow(img,cmap='binary')\n",
    "plt.title(train_labels.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88700000000000001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_images, train_labels.values.ravel())\n",
    "clf.score(test_images,test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(test_set_location)\n",
    "test_data[test_data>0]=1\n",
    "results=clf.predict(test_data[0:5000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting Questions:\n",
    "\n",
    "- Why is large margin better than smaller?\n",
    "    - large margin is more likely to correctly classify new data\n",
    "    - think margin as confidence (can we treat margin as confidence in a statistical setting?), when a new point comes, (assume it is close to the points of same category), it is less likely to be misclassified\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs Rest\n",
    "$$\\DeclareMathOperator*{\\argmax}{arg\\,max}$$\n",
    "For $k$ classes, we construct $k$ functions $f_i(x)$ for $i = 1, \\cdots, k$, designed to estimate the probability for $x$ is in class $i$.\n",
    "\n",
    "We train $f_i(x)$ with labeled data:  $y = 1$ if $x \\in C$ and $y = 0$ if $x$ is in any other class.  The predicted class label for $x$ is\n",
    "\n",
    "$$\\argmax_i f_i(x)$$\n",
    "\n",
    "#### Margin in One vs Rest\n",
    "\n",
    "In multiclass case, **margin** is defined as \n",
    "\n",
    "$$f_y(x) - f_j(x) \\geq 1$$\n",
    "\n",
    "where $y$ is the correct label class corresponding to $x$, and $j$ is any other class\n",
    "\n",
    "So, loss is defined as \n",
    "$$\\max(0, 1 - (f_y(x) - f_j(x)))$$\n",
    "\n",
    "for one case, the total loss is\n",
    "\n",
    "$$l = \\sum_{j \\neq y} \\max\\big(0, 1 - f_y(x) + f_j(x)\\big)$$\n",
    "### One vs One\n",
    "\n",
    "For $k$ classes, we construct $\\binom{k}{2}$ functions $f_{ij}(x)$ with $i < j \\in \\{1, \\cdots, k\\}$  Each $f_{i,j}(x)$ is a binary classifier for class $i$ and class $j$, and is trianedon those classes.  For a new instance $x$, tally the vote from all $\\binom{k}{2}$ classifiers.  Outputs the class with highest votes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
