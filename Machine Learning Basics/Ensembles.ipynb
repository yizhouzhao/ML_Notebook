{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions:\n",
    "\n",
    "**Ensemble**: A model built from many simpler models\n",
    "\n",
    "**Bagging**(Bootstrap AGgregation): Train base models on bootstrap samples of the data. Take majority vote for classification tasks, or average output for regression.\n",
    "- Models trained independently\n",
    "- Reduces variance in the prediction, not bias\n",
    "- What happens if the errors are independent?\n",
    "- Often used with deep learning models (independence allows parallelization)\n",
    "\n",
    "**Boosting**: Learners are ordered. Each learner tries to reduce error (residual) on “hard” examples, which are those misclassified by earlier learners. \n",
    "- Models are dependent, trained sequentially\n",
    "- ADABOOST\n",
    "- GRADIENT BOOST\n",
    "- Reduces bias and possibly variance compared to base learners\n",
    "-  Rarely used with deep learning models, are deep models bias?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Approaches\n",
    "\n",
    "**True Ensemble**:   train several models independently.\n",
    "\n",
    "- Prediction averaging: averaged predicted probabilities, or just vote. Always works. \n",
    "\n",
    "- Parameter averaging: average the parametersof the models. Almost never works (too many different equivalent parametrizations).\n",
    "\n",
    "**Pseudo-Ensembles**:  Train one model, but different, independent tails.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Snapshots**: Just keep training a single base model (with fairly high learning rate), and take periodic snapshots of its parameters.\n",
    "- Prediction averaging: Always works. \n",
    "- Parameter averaging: Often works! Snapshots are sufficiently close in parameter space!\n",
    "    - Parameter averaging means you only need to keep a single modelfor future predictions. If you use a moving average of the snapshots, you only keep one extra set of parameters. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
